# Q3 <- quantile(data$eccif_amount,na.rm = TRUE, 0.95)
# IQR <- Q3 - Q1
# lower_fence <- Q1 - 1.5 * IQR
# upper_fence <- Q3 + 1.5 * IQR
# Remove Outliers
# data <- data %>%
#   filter(eccif_amount >= lower_fence & eccif_amount <= upper_fence)
#Filter for me where created_date and admission_date are not NA
data <- data %>%
filter(!is.na(created_date))
# Assuming 'Claims_Data_PPO' is your dataset
data <- data %>%
mutate(Delay_in_Days = as.numeric(difftime(created_date, admission_date, units = "days")))
#Calculate the mean delay in days
mean(data$Delay_in_Days, na.rm=TRUE)
data <- data %>%
mutate(check = ifelse(created_date >= admission_date,'True','False'))
# Checking number of True and False Checks
check_counts <- table(data$check)
# Print the result
print(check_counts)
# Creating Adjusted_Tran_date, Ser_Year, Acc_Months, and Dev_period columns in the 'Claims_Data_PPO'dataset
data <- data %>%
mutate(
Adjusted_created_date = if_else(check == 'False', admission_date + days(3), created_date),
Acc_Months_ = as.yearmon(admission_date),
Acc_Year = as.integer(format(Acc_Months_, "%Y")),
Acc_Month = as.integer(format(Acc_Months_, "%m")),
Acc_Months = (Acc_Year - min(Acc_Year, na.rm = TRUE)) * 12 + Acc_Month - min(Acc_Month, na.rm = TRUE) + 1,
Loss_Year = year(admission_date),
Dev_period = floor(difftime(Adjusted_created_date, admission_date, units = "days") / (365.25/12)) + 1
)
# Generate Acc_period
Periods <- data %>%
filter(Loss_Year>2020) %>%
distinct(Acc_Months) %>%
nrow()
Acc_period <- data %>%
filter(Loss_Year > 2020) %>%
select(Acc_Months) %>%
distinct() %>%
arrange(Acc_Months) %>%
rowwise() %>%
mutate(Dev_period = list(seq(1, Periods, 1))) %>%
unnest(Dev_period)
# Filter data based on val_class
Val_Data <- data %>%
select(Acc_Months, eccif_amount, Dev_period) %>%
mutate(eccif_amount = as.numeric(gsub("[^0-9.]", "", eccif_amount))) %>%
group_by(Acc_Months, Dev_period) %>%
summarise(Gross_Amount = sum(eccif_amount, na.rm = TRUE)) %>%
mutate(Dev_period = as.numeric(as.character(Dev_period))) %>%
right_join(Acc_period, by = c("Acc_Months", "Dev_period"))
# Create triangles
Inc_Tri <- as.triangle(Val_Data,
origin = "Acc_Months",
dev = "Dev_period",
value = "Gross_Amount")
# Convert to cumulative
Cum_Tri <- incr2cum(Inc_Tri)
# Perform Bootstrap
Boot_Method <- BootChainLadder(Cum_Tri, R = 9999, process.distr = "od.pois")
# Summary
summary_Boot_Method <- summary(Boot_Method)$Totals
view(summary_Boot_Method)
# Confidence levels
confidence_level <- quantile(Boot_Method, c(0.75))
confidence_level <- confidence_level$ByOrigin
View(confidence_level)
library(tidyverse)
library(readxl)
library(rio)
library(dplyr)
library(tidyr)
library(ChainLadder)
library(lubridate)
library(readr)
library(zoo)
library(data.table)
path <- "C:/Users/Robin Ochieng.BEN-ODHIAMBO/OneDrive - Kenbright/Attachments/projects/2026/February/SHA Risk Adjustment/Data/data.csv"
data <- read_csv(path)
#SME Lines
val_class <- c("ECCIF")
data <- data %>%
filter(fund %in% val_class)
# Calculate IQR and Tukey's Fences
Q1 <- quantile(data$eccif_amount,na.rm = TRUE, 0.05)
Q3 <- quantile(data$eccif_amount,na.rm = TRUE, 0.95)
IQR <- Q3 - Q1
lower_fence <- Q1 - 1.5 * IQR
upper_fence <- Q3 + 1.5 * IQR
# Remove Outliers
data <- data %>%
filter(eccif_amount >= lower_fence & eccif_amount <= upper_fence)
#Filter for me where created_date and admission_date are not NA
data <- data %>%
filter(!is.na(created_date))
# Assuming 'Claims_Data_PPO' is your dataset
data <- data %>%
mutate(Delay_in_Days = as.numeric(difftime(created_date, admission_date, units = "days")))
#Calculate the mean delay in days
mean(data$Delay_in_Days, na.rm=TRUE)
data <- data %>%
mutate(check = ifelse(created_date >= admission_date,'True','False'))
# Checking number of True and False Checks
check_counts <- table(data$check)
# Print the result
print(check_counts)
# Creating Adjusted_Tran_date, Ser_Year, Acc_Months, and Dev_period columns in the 'Claims_Data_PPO'dataset
data <- data %>%
mutate(
Adjusted_created_date = if_else(check == 'False', admission_date + days(7), created_date),
Acc_Months_ = as.yearmon(admission_date),
Acc_Year = as.integer(format(Acc_Months_, "%Y")),
Acc_Month = as.integer(format(Acc_Months_, "%m")),
Acc_Months = (Acc_Year - min(Acc_Year, na.rm = TRUE)) * 12 + Acc_Month - min(Acc_Month, na.rm = TRUE) + 1,
Loss_Year = year(admission_date),
Dev_period = floor(difftime(Adjusted_created_date, admission_date, units = "days") / (365.25/12)) + 1
)
# Generate Acc_period
Periods <- data %>%
filter(Loss_Year>2020) %>%
distinct(Acc_Months) %>%
nrow()
Acc_period <- data %>%
filter(Loss_Year > 2020) %>%
select(Acc_Months) %>%
distinct() %>%
arrange(Acc_Months) %>%
rowwise() %>%
mutate(Dev_period = list(seq(1, Periods, 1))) %>%
unnest(Dev_period)
# Filter data based on val_class
Val_Data <- data %>%
select(Acc_Months, eccif_amount, Dev_period) %>%
mutate(eccif_amount = as.numeric(gsub("[^0-9.]", "", eccif_amount))) %>%
group_by(Acc_Months, Dev_period) %>%
summarise(Gross_Amount = sum(eccif_amount, na.rm = TRUE)) %>%
mutate(Dev_period = as.numeric(as.character(Dev_period))) %>%
right_join(Acc_period, by = c("Acc_Months", "Dev_period"))
# Create triangles
Inc_Tri <- as.triangle(Val_Data,
origin = "Acc_Months",
dev = "Dev_period",
value = "Gross_Amount")
# Convert to cumulative
Cum_Tri <- incr2cum(Inc_Tri)
# Perform Bootstrap
Boot_Method <- BootChainLadder(Cum_Tri, R = 9999, process.distr = "od.pois")
# Summary
summary_Boot_Method <- summary(Boot_Method)$Totals
view(summary_Boot_Method)
# Confidence levels
confidence_level <- quantile(Boot_Method, c(0.75))
confidence_level <- confidence_level$ByOrigin
View(confidence_level)
library(tidyverse)
library(readxl)
library(rio)
library(dplyr)
library(tidyr)
library(ChainLadder)
library(lubridate)
library(readr)
library(zoo)
library(data.table)
path <- "C:/Users/Robin Ochieng.BEN-ODHIAMBO/OneDrive - Kenbright/Attachments/projects/2026/February/SHA Risk Adjustment/Data/data.csv"
data <- read_csv(path)
#SME Lines
val_class <- c("ECCIF")
data <- data %>%
filter(fund %in% val_class)
# Calculate IQR and Tukey's Fences
Q1 <- quantile(data$eccif_amount,na.rm = TRUE, 0.10)
Q3 <- quantile(data$eccif_amount,na.rm = TRUE, 0.90)
IQR <- Q3 - Q1
lower_fence <- Q1 - 1.5 * IQR
upper_fence <- Q3 + 1.5 * IQR
# Remove Outliers
data <- data %>%
filter(eccif_amount >= lower_fence & eccif_amount <= upper_fence)
#Filter for me where created_date and admission_date are not NA
data <- data %>%
filter(!is.na(created_date))
# Assuming 'Claims_Data_PPO' is your dataset
data <- data %>%
mutate(Delay_in_Days = as.numeric(difftime(created_date, admission_date, units = "days")))
#Calculate the mean delay in days
mean(data$Delay_in_Days, na.rm=TRUE)
data <- data %>%
mutate(check = ifelse(created_date >= admission_date,'True','False'))
# Checking number of True and False Checks
check_counts <- table(data$check)
# Print the result
print(check_counts)
# Creating Adjusted_Tran_date, Ser_Year, Acc_Months, and Dev_period columns in the 'Claims_Data_PPO'dataset
data <- data %>%
mutate(
Adjusted_created_date = if_else(check == 'False', admission_date + days(7), created_date),
Acc_Months_ = as.yearmon(admission_date),
Acc_Year = as.integer(format(Acc_Months_, "%Y")),
Acc_Month = as.integer(format(Acc_Months_, "%m")),
Acc_Months = (Acc_Year - min(Acc_Year, na.rm = TRUE)) * 12 + Acc_Month - min(Acc_Month, na.rm = TRUE) + 1,
Loss_Year = year(admission_date),
Dev_period = floor(difftime(Adjusted_created_date, admission_date, units = "days") / (365.25/12)) + 1
)
# Generate Acc_period
Periods <- data %>%
filter(Loss_Year>2020) %>%
distinct(Acc_Months) %>%
nrow()
Acc_period <- data %>%
filter(Loss_Year > 2020) %>%
select(Acc_Months) %>%
distinct() %>%
arrange(Acc_Months) %>%
rowwise() %>%
mutate(Dev_period = list(seq(1, Periods, 1))) %>%
unnest(Dev_period)
# Filter data based on val_class
Val_Data <- data %>%
select(Acc_Months, eccif_amount, Dev_period) %>%
mutate(eccif_amount = as.numeric(gsub("[^0-9.]", "", eccif_amount))) %>%
group_by(Acc_Months, Dev_period) %>%
summarise(Gross_Amount = sum(eccif_amount, na.rm = TRUE)) %>%
mutate(Dev_period = as.numeric(as.character(Dev_period))) %>%
right_join(Acc_period, by = c("Acc_Months", "Dev_period"))
# Create triangles
Inc_Tri <- as.triangle(Val_Data,
origin = "Acc_Months",
dev = "Dev_period",
value = "Gross_Amount")
# Convert to cumulative
Cum_Tri <- incr2cum(Inc_Tri)
# Perform Bootstrap
Boot_Method <- BootChainLadder(Cum_Tri, R = 9999, process.distr = "od.pois")
# Summary
summary_Boot_Method <- summary(Boot_Method)$Totals
view(summary_Boot_Method)
# Confidence levels
confidence_level <- quantile(Boot_Method, c(0.75))
confidence_level <- confidence_level$ByOrigin
View(confidence_level)
library(tidyverse)
library(readxl)
library(rio)
library(dplyr)
library(tidyr)
library(ChainLadder)
library(lubridate)
library(readr)
library(zoo)
library(data.table)
path <- "C:/Users/Robin Ochieng.BEN-ODHIAMBO/OneDrive - Kenbright/Attachments/projects/2026/February/SHA Risk Adjustment/Data/data.csv"
data <- read_csv(path)
#SME Lines
val_class <- c("ECCIF")
data <- data %>%
filter(fund %in% val_class)
# Calculate IQR and Tukey's Fences
Q1 <- quantile(data$eccif_amount,na.rm = TRUE, 0.15)
Q3 <- quantile(data$eccif_amount,na.rm = TRUE, 0.85)
IQR <- Q3 - Q1
lower_fence <- Q1 - 1.5 * IQR
upper_fence <- Q3 + 1.5 * IQR
# Remove Outliers
data <- data %>%
filter(eccif_amount >= lower_fence & eccif_amount <= upper_fence)
#Filter for me where created_date and admission_date are not NA
data <- data %>%
filter(!is.na(created_date))
# Assuming 'Claims_Data_PPO' is your dataset
data <- data %>%
mutate(Delay_in_Days = as.numeric(difftime(created_date, admission_date, units = "days")))
#Calculate the mean delay in days
mean(data$Delay_in_Days, na.rm=TRUE)
data <- data %>%
mutate(check = ifelse(created_date >= admission_date,'True','False'))
# Checking number of True and False Checks
check_counts <- table(data$check)
# Print the result
print(check_counts)
# Creating Adjusted_Tran_date, Ser_Year, Acc_Months, and Dev_period columns in the 'Claims_Data_PPO'dataset
data <- data %>%
mutate(
Adjusted_created_date = if_else(check == 'False', admission_date + days(7), created_date),
Acc_Months_ = as.yearmon(admission_date),
Acc_Year = as.integer(format(Acc_Months_, "%Y")),
Acc_Month = as.integer(format(Acc_Months_, "%m")),
Acc_Months = (Acc_Year - min(Acc_Year, na.rm = TRUE)) * 12 + Acc_Month - min(Acc_Month, na.rm = TRUE) + 1,
Loss_Year = year(admission_date),
Dev_period = floor(difftime(Adjusted_created_date, admission_date, units = "days") / (365.25/12)) + 1
)
# Generate Acc_period
Periods <- data %>%
filter(Loss_Year>2020) %>%
distinct(Acc_Months) %>%
nrow()
Acc_period <- data %>%
filter(Loss_Year > 2020) %>%
select(Acc_Months) %>%
distinct() %>%
arrange(Acc_Months) %>%
rowwise() %>%
mutate(Dev_period = list(seq(1, Periods, 1))) %>%
unnest(Dev_period)
# Filter data based on val_class
Val_Data <- data %>%
select(Acc_Months, eccif_amount, Dev_period) %>%
mutate(eccif_amount = as.numeric(gsub("[^0-9.]", "", eccif_amount))) %>%
group_by(Acc_Months, Dev_period) %>%
summarise(Gross_Amount = sum(eccif_amount, na.rm = TRUE)) %>%
mutate(Dev_period = as.numeric(as.character(Dev_period))) %>%
right_join(Acc_period, by = c("Acc_Months", "Dev_period"))
# Create triangles
Inc_Tri <- as.triangle(Val_Data,
origin = "Acc_Months",
dev = "Dev_period",
value = "Gross_Amount")
# Convert to cumulative
Cum_Tri <- incr2cum(Inc_Tri)
# Perform Bootstrap
Boot_Method <- BootChainLadder(Cum_Tri, R = 9999, process.distr = "od.pois")
# Summary
summary_Boot_Method <- summary(Boot_Method)$Totals
view(summary_Boot_Method)
# Confidence levels
confidence_level <- quantile(Boot_Method, c(0.75))
confidence_level <- confidence_level$ByOrigin
View(confidence_level)
library(tidyverse)
library(readxl)
library(rio)
library(dplyr)
library(tidyr)
library(ChainLadder)
library(lubridate)
library(readr)
library(zoo)
library(data.table)
path <- "C:/Users/Robin Ochieng.BEN-ODHIAMBO/OneDrive - Kenbright/Attachments/projects/2026/February/SHA Risk Adjustment/Data/data.csv"
data <- read_csv(path)
data <- data %>%
mutate(
shif_amt = coalesce(oop_amount, 0) + coalesce(shif_amount, 0))
#SME Lines
val_class <- c("SHIF", "OOP")
data <- data %>%
filter(fund %in% val_class)
# Calculate IQR and Tukey's Fences
Q1 <- quantile(data$shif_amt,na.rm = TRUE, 0.15)
Q3 <- quantile(data$shif_amt,na.rm = TRUE, 0.85)
IQR <- Q3 - Q1
lower_fence <- Q1 - 1.5 * IQR
upper_fence <- Q3 + 1.5 * IQR
# Remove Outliers
data <- data %>%
filter(shif_amt >= lower_fence & shif_amt <= upper_fence)
#Filter for me where created_date and admission_date are not NA
data <- data %>%
filter(!is.na(created_date))
# Assuming 'Claims_Data_PPO' is your dataset
data <- data %>%
mutate(Delay_in_Days = as.numeric(difftime(created_date, admission_date, units = "days")))
#Calculate the mean delay in days
mean(data$Delay_in_Days, na.rm=TRUE)
data <- data %>%
mutate(check = ifelse(created_date >= admission_date,'True','False'))
# Checking number of True and False Checks
check_counts <- table(data$check)
# Print the result
print(check_counts)
# Creating Adjusted_Tran_date, Ser_Year, Acc_Months, and Dev_period columns in the 'Claims_Data_PPO'dataset
data <- data %>%
mutate(
Adjusted_created_date = if_else(check == 'False', admission_date + days(7), created_date),
Acc_Months_ = as.yearmon(admission_date),
Acc_Year = as.integer(format(Acc_Months_, "%Y")),
Acc_Month = as.integer(format(Acc_Months_, "%m")),
Acc_Months = (Acc_Year - min(Acc_Year, na.rm = TRUE)) * 12 + Acc_Month - min(Acc_Month, na.rm = TRUE) + 1,
Loss_Year = year(admission_date),
Dev_period = floor(difftime(Adjusted_created_date, admission_date, units = "days") / (365.25/12)) + 1
)
# Generate Acc_period
Periods <- data %>%
filter(Loss_Year>2020) %>%
distinct(Acc_Months) %>%
nrow()
Acc_period <- data %>%
filter(Loss_Year > 2020) %>%
select(Acc_Months) %>%
distinct() %>%
arrange(Acc_Months) %>%
rowwise() %>%
mutate(Dev_period = list(seq(1, Periods, 1))) %>%
unnest(Dev_period)
# Filter data based on val_class
Val_Data <- data %>%
select(Acc_Months, shif_amt, Dev_period) %>%
mutate(shif_amt = as.numeric(gsub("[^0-9.]", "", shif_amt))) %>%
group_by(Acc_Months, Dev_period) %>%
summarise(Gross_Amount = sum(shif_amt, na.rm = TRUE)) %>%
mutate(Dev_period = as.numeric(as.character(Dev_period))) %>%
right_join(Acc_period, by = c("Acc_Months", "Dev_period"))
# Create triangles
Inc_Tri <- as.triangle(Val_Data,
origin = "Acc_Months",
dev = "Dev_period",
value = "Gross_Amount")
# Convert to cumulative
Cum_Tri <- incr2cum(Inc_Tri)
# Perform Bootstrap
Boot_Method <- BootChainLadder(Cum_Tri, R = 9999, process.distr = "od.pois")
# Summary
summary_Boot_Method <- summary(Boot_Method)$Totals
view(summary_Boot_Method)
# Confidence levels
confidence_level <- quantile(Boot_Method, c(0.75))
confidence_level <- confidence_level$ByOrigin
View(confidence_level)
library(tidyverse)
library(readxl)
library(rio)
library(dplyr)
library(tidyr)
library(ChainLadder)
library(lubridate)
library(readr)
library(zoo)
library(data.table)
path <- "C:/Users/Robin Ochieng.BEN-ODHIAMBO/OneDrive - Kenbright/Attachments/projects/2026/February/SHA Risk Adjustment/Data/data.csv"
data <- read_csv(path)
data <- data %>%
mutate(
shif_amt = coalesce(oop_amount, 0) + coalesce(shif_amount, 0))
#SME Lines
val_class <- c("SHIF", "OOP")
data <- data %>%
filter(fund %in% val_class)
# Calculate IQR and Tukey's Fences
Q1 <- quantile(data$shif_amt,na.rm = TRUE, 0.10)
Q3 <- quantile(data$shif_amt,na.rm = TRUE, 0.90)
IQR <- Q3 - Q1
lower_fence <- Q1 - 1.5 * IQR
upper_fence <- Q3 + 1.5 * IQR
# Remove Outliers
data <- data %>%
filter(shif_amt >= lower_fence & shif_amt <= upper_fence)
#Filter for me where created_date and admission_date are not NA
data <- data %>%
filter(!is.na(created_date))
# Assuming 'Claims_Data_PPO' is your dataset
data <- data %>%
mutate(Delay_in_Days = as.numeric(difftime(created_date, admission_date, units = "days")))
#Calculate the mean delay in days
mean(data$Delay_in_Days, na.rm=TRUE)
data <- data %>%
mutate(check = ifelse(created_date >= admission_date,'True','False'))
# Checking number of True and False Checks
check_counts <- table(data$check)
# Print the result
print(check_counts)
# Creating Adjusted_Tran_date, Ser_Year, Acc_Months, and Dev_period columns in the 'Claims_Data_PPO'dataset
data <- data %>%
mutate(
Adjusted_created_date = if_else(check == 'False', admission_date + days(7), created_date),
Acc_Months_ = as.yearmon(admission_date),
Acc_Year = as.integer(format(Acc_Months_, "%Y")),
Acc_Month = as.integer(format(Acc_Months_, "%m")),
Acc_Months = (Acc_Year - min(Acc_Year, na.rm = TRUE)) * 12 + Acc_Month - min(Acc_Month, na.rm = TRUE) + 1,
Loss_Year = year(admission_date),
Dev_period = floor(difftime(Adjusted_created_date, admission_date, units = "days") / (365.25/12)) + 1
)
# Generate Acc_period
Periods <- data %>%
filter(Loss_Year>2020) %>%
distinct(Acc_Months) %>%
nrow()
Acc_period <- data %>%
filter(Loss_Year > 2020) %>%
select(Acc_Months) %>%
distinct() %>%
arrange(Acc_Months) %>%
rowwise() %>%
mutate(Dev_period = list(seq(1, Periods, 1))) %>%
unnest(Dev_period)
# Filter data based on val_class
Val_Data <- data %>%
select(Acc_Months, shif_amt, Dev_period) %>%
mutate(shif_amt = as.numeric(gsub("[^0-9.]", "", shif_amt))) %>%
group_by(Acc_Months, Dev_period) %>%
summarise(Gross_Amount = sum(shif_amt, na.rm = TRUE)) %>%
mutate(Dev_period = as.numeric(as.character(Dev_period))) %>%
right_join(Acc_period, by = c("Acc_Months", "Dev_period"))
# Create triangles
Inc_Tri <- as.triangle(Val_Data,
origin = "Acc_Months",
dev = "Dev_period",
value = "Gross_Amount")
# Convert to cumulative
Cum_Tri <- incr2cum(Inc_Tri)
# Perform Bootstrap
Boot_Method <- BootChainLadder(Cum_Tri, R = 9999, process.distr = "od.pois")
# Summary
summary_Boot_Method <- summary(Boot_Method)$Totals
view(summary_Boot_Method)
# Confidence levels
confidence_level <- quantile(Boot_Method, c(0.75))
confidence_level <- confidence_level$ByOrigin
View(confidence_level)
shiny::runApp('C:/Users/Robin Ochieng.BEN-ODHIAMBO/OneDrive - Kenbright/Attachments/projects/2026/January/Exposure Frequency and Severity Updated/Exposure-Frequency-and-Severity-Model')
shiny::runApp('C:/Users/Robin Ochieng.BEN-ODHIAMBO/OneDrive - Kenbright/Attachments/projects/2026/January/Exposure Frequency and Severity Updated/Exposure-Frequency-and-Severity-Model')
